# An√°lisis del Producto: NEST (NSMP Endometrial Stratification Tool)

Este documento detalla la arquitectura funcional de la aplicaci√≥n, dividiendo claramente entre la herramienta cl√≠nica operativa y la base cient√≠fica demostrativa, analizando el estado actual y proponiendo mejoras para el producto final.

---

## 1. La Calculadora Cl√≠nica (Herramienta para el Profesional)

Esta secci√≥n es el **producto core** que utilizar√°n los onc√≥logos y ginec√≥logos. Su foco es la **usabilidad, la explicabilidad y el apoyo a la decisi√≥n**.

### üèóÔ∏è Qu√© hay implementado:
1.  **Motor de Predicci√≥n (Backend):**
    *   Modelo de **Regresi√≥n Log√≠stica Regularizada (Ridge)**.
    *   Predice probabilidad exacta (0-100%) y grupo de riesgo (Bajo/Interm/Alto/Muy Alto).
    *   Genera recomendaciones cl√≠nicas basadas en gu√≠as ESGO/ESTRO.
2.  **Explicabilidad Avanzada (XAI):**
    *   **Lenguaje Natural:** El backend genera un p√°rrafo explicando *por qu√©* ese resultado (ej. "Riesgo elevado principalmente por LVSI y Grado 2").
    *   **Factores de Riesgo:** Lista expl√≠cita de variables que contribuyen negativamente.
    *   **Waterfall Chart:** Gr√°fico que muestra cu√°nto suma o resta cada variable al riesgo base.
    *   **An√°lisis What-If:** M√≥dulo interactivo para simular escenarios (ej. "¬øBajar√≠a el riesgo si el tumor fuera menor de 2cm?").
3.  **Herramientas de Apoyo (NEST+):**
    *   **Curvas de Supervivencia $S(t)$:** Modelo Cox Proportional Hazards que predice la probabilidad de *no recidiva* a 1, 3 y 5 a√±os personalizada para la paciente.
    *   **Pacientes Similares (KNN):** Algoritmo que busca en la base de datos hist√≥rica los casos m√°s parecidos cl√≠nica y molecularmente.
    *   **Comparaci√≥n Cohorte:** Contextualiza a la paciente respecto al promedio del hospital.

---

## 2. El M√≥dulo Cient√≠fico (Herramienta para la Demo/Jurado)

Esta secci√≥n es nuestra **"sala de trofeos" t√©cnica**. Su objetivo es demostrar el rigor cient√≠fico, el proceso de ingenier√≠a y validar por qu√© nuestro modelo es confiable.

### üß™ Qu√© hay implementado:
1.  **Metodolog√≠a "Del Dato al Modelo":**
    *   **Ingenier√≠a de Datos:**
        *   Dataset: 154 pacientes NSMP (Hospital Sant Pau).
        *   **Imputaci√≥n:** Estrategia h√≠brida (Mediana para num√©ricas, Moda para categ√≥ricas) para no perder ni un solo paciente (n=154 es peque√±o, cada dato cuenta).
        *   **Feature Engineering:**
            *   Creaci√≥n de `mmr_deficient` (combinando 4 prote√≠nas).
            *   Normalizaci√≥n Z-score `(x - mean) / std` para todas las variables continuas.
        *   **Control de Sesgos:** Exclusi√≥n expl√≠cita de variables de tratamiento (Radioterapia/Quimioterapia) para evitar *Confounding by indication* (evitar que el modelo aprenda que "Recibir quimio = Morir", cuando es al rev√©s: se da quimio a los graves).
2.  **Validaci√≥n Rigurosa:**
    *   **Comparativa de Modelos:**
        *   *Random Forest:* Mayor AUC (0.97) pero "Caja Negra" y tendencia al overfitting.
        *   *Regresi√≥n Log√≠stica L2:* AUC excelente (0.93), calibraci√≥n perfecta e interpretabilidad total. **Modelo Elegido.**
    *   **M√©tricas:** AUC-ROC, Sensibilidad/Especificidad, Brier Score (Calibraci√≥n).
3.  **Visualizaciones Est√°ticas:**
    *   Curvas ROC y de Calibraci√≥n.
    *   Matrices de Confusi√≥n y Correlaci√≥n.
    *   Importancia de Variables (Feature Importance).

---

## 3. An√°lisis de Gaps y Estrategia de Mejora ("El Producto Perfecto")

Para ganar la hackathon, debemos pulir las fricciones entre la potencia t√©cnica y la experiencia de usuario.

### üî¥ Gaps Identificados (Lo que falla o falta)

#### A. En la Calculadora (Backend/Frontend)
1.  **Discrepancia Modelo vs API:**
    *   *Problema:* El script de entrenamiento (`model.py`) actualmente dice que el **Random Forest** es el mejor (AUC 0.97), pero la API (`api.py`) tiene hardcodeados los coeficientes de la **Regresi√≥n Log√≠stica**.
    *   *Riesgo:* Si un juez pregunta "¬øPor qu√© no usas el modelo de 0.97?", la respuesta "por explicabilidad" es v√°lida pero debemos ser consistentes.
2.  **Velocidad de Respuesta:**
    *   El entrenamiento ocurre "on startup" si no hay `.pkl`. Esto puede ralentizar el primer arranque en la demo.

#### B. En la Parte Cient√≠fica
1.  **Est√°tica vs Din√°mica:**
    *   Los gr√°ficos en `/scientific` son im√°genes est√°ticas (`.png`). No se pueden hacer zoom ni interactuar.
2.  **Historia Incompleta:**
    *   Falta enfatizar m√°s el valor de los datos *moleculares* (p53, receptores) vs los cl√≠nicos tradicionales. Es el *selling point* del proyecto ("NSMP no es un caj√≥n de sastre, hay biolog√≠a detr√°s").

### üü¢ Soluciones Propuestas

1.  **Consolidar la Decisi√≥n del Modelo (Hybrid Approach):**
    *   Mantener la **Regresi√≥n Log√≠stica** para el *Score de Riesgo* y la *Explicabilidad* (Waterfall, What-if).
    *   Usar el **Random Forest** (si es superior) *solo* para la b√∫squeda de **Pacientes Similares** (KNN usa features, RF selecciona features importantes).
    *   *Acci√≥n:* Asegurar que `api.py` y `Scientific.tsx` cuenten la misma historia: "Elegimos Log√≠stica por seguridad cl√≠nica, aunque RF ten√≠a un margen m√©trico superior despreciable".

2.  **Mejorar la UX de "Validaci√≥n":**
    *   En la pesta√±a "Validaci√≥n Batch" de la calculadora, a√±adir un bot√≥n para "Re-entrenar con mis propios datos" (simulado o real). Eso volar√≠a la cabeza al jurado (MLOps en el navegador).

3.  **Reforzar la Narrativa Molecular en Scientific:**
    *   A√±adir un bloque espec√≠fico en la metodolog√≠a sobre c√≥mo el perfil molecular (p53/ER/PR) cambia el pron√≥stico en pacientes que cl√≠nicamente parecen iguales.

4.  **Polish Visual:**
    *   Asegurar que los colores de riesgo (Verde/Naranja/Rojo/Morado) sean consistentes en TODA la app (gr√°ficos, badges, textos).
